"""
Este script aplica un modelo de Regresi√≥n Log√≠stica para predecir si un 
estudiante se graduar√° o abandonar√° sus estudios.

Pregunta de Investigaci√≥n: 
"¬øEs posible predecir el abandono acad√©mico o √©xito de un estudiante 
utilizando t√©cnicas estad√≠sticas y de clasificaci√≥n?"

Modelo utilizado: Regresi√≥n Log√≠stica
- Ideal para clasificaci√≥n binaria (Dropout vs Graduate)
"""
import pandas as pd                                      # Manipulaci√≥n de datos tabulares
import numpy as np                                       # Operaciones num√©ricas y arrays
import matplotlib.pyplot as plt                          # Creaci√≥n de gr√°ficos
import seaborn as sns                                    # Visualizaciones estad√≠sticas
import warnings                                          # Manejo de advertencias
import json                                              # Guardado/carga de resultados
import os                                                # Operaciones del sistema
from datetime import datetime                            # Timestamps
from scipy.stats import zscore                           # C√°lculo de z-scores
import statsmodels.api as sm                             # Modelos estad√≠sticos
from statsmodels.formula.api import logit                # Regresi√≥n log√≠stica con f√≥rmulas
from statsmodels.tools.tools import add_constant         # Agregar constante al modelo
from statsmodels.stats.outliers_influence import variance_inflation_factor  # C√°lculo de VIF
from statsmodels.tools.sm_exceptions import ConvergenceWarning              # Manejo de warnings
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold  # Divisi√≥n y CV
from sklearn.linear_model import LogisticRegression                                     # Modelo de clasificaci√≥n
from sklearn.preprocessing import StandardScaler                                        # Estandarizaci√≥n de features
from sklearn.feature_selection import SelectKBest, f_classif, RFE   # M√©todos de selecci√≥n

# M√©tricas de evaluaci√≥n del modelo:
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    precision_score, recall_score, f1_score, roc_auc_score, roc_curve,
    precision_recall_curve, average_precision_score
)

# Suprimir advertencias para salida m√°s limpia
warnings.filterwarnings('ignore')
warnings.filterwarnings("ignore", category=ConvergenceWarning)

# CONFIGURACI√ìN VISUAL
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.figsize'] = (12, 8)  # Tama√±o por defecto de figuras
plt.rcParams['font.size'] = 12            # Tama√±o de fuente legible

# CONFIGURACI√ìN DE RUTAS Y PAR√ÅMETROS
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)

# Rutas de entrada y salida
INPUT_PATH = os.path.join(PROJECT_ROOT, "outputs", "prepared_data", "dataset_prepared.csv")
OUTPUT_DIR = os.path.join(PROJECT_ROOT, "outputs", "prediction_results")

# Par√°metros del modelo - importantes para reproducibilidad
RANDOM_STATE = 42   # Semilla para reproducibilidad de resultados
TEST_SIZE = 0.20    # 20% de datos para prueba, 80% para entrenamiento

# Crear directorio de salida si no existe
os.makedirs(OUTPUT_DIR, exist_ok=True)

def load_and_prepare_data(filepath):
    """
    Cargar el dataset preparado y filtrar para clasificaci√≥n binaria.
    Filtramos solo 'Dropout' y 'Graduate'
    
    La variable objetivo se codifica como:
    - 1 = Graduate (Graduado - √©xito)
    - 0 = Dropout (Abandono)
    
    El dataset resultante cumple los dos supuestos fundamentales para la regresi√≥n log√≠stica:
    1. Supuesto de variable dependiente binaria: la variable objetivo tiene solo dos categor√≠as (0 = Dropout, 1 = Graduate).
    2. Supuesto de independencia de las observaciones: se eliminan filas duplicadas, asegurando que cada fila representa una observaci√≥n √∫nica e independiente.
    """
    print("=" * 70)
    print("CARGA Y PREPARACI√ìN DE DATOS (VARIABLE OBJ. BINARIA E INDEPENDENCIA)")
    print("=" * 70)
    
    df = pd.read_csv(filepath)
    print(f"\nüìä Dataset original shape: {df.shape}")
    
    # Show distribution of target variable
    print("\nüìà Distribuci√≥n original de la variable Target:")
    target_counts = df['Target'].value_counts()
    for target, count in target_counts.items():
        percentage = count / len(df) * 100
        print(f"   - {target}: {count} ({percentage:.1f}%)")
    
    # Filter only Dropout and Graduate (exclude Enrolled students)
    df_filtered = df[df['Target'].isin(['Dropout', 'Graduate'])].copy()
    
    print(f"\nüìä Dataset filtrado (solo Dropout y Graduate): {df_filtered.shape}")
    print("\nüìà Distribuci√≥n del dataset filtrado:")
    target_counts_filtered = df_filtered['Target'].value_counts()
    for target, count in target_counts_filtered.items():
        percentage = count / len(df_filtered) * 100
        print(f"   - {target}: {count} ({percentage:.1f}%)")
    
    # Create binary target: 1 = Graduate (Success), 0 = Dropout
    df_filtered['Target_binary'] = (df_filtered['Target'] == 'Graduate').astype(int)

    print("Supuesto de variable dependiente binaria (se cumple): la variable objetivo tiene solo dos categor√≠as (0 = Dropout, 1 = Graduate).")

    # Comprobar independencia de las observaciones (filas duplicadas)
    duplicated_rows = df_filtered.duplicated()
    num_duplicates = duplicated_rows.sum()
    if num_duplicates > 0:
        print(f"Advertencia: Se encontraron {num_duplicates} filas no independientes (duplicadas). Ser√°n eliminadas.")
        df_filtered = df_filtered[~duplicated_rows].copy()
        print(f"Supuesto de independencia de las observaciones (se cumple): se eliminaron {num_duplicates} filas duplicadas. Luego de las transformaciones se logr√≥ la independencia de las observaciones.\nCada fila del dataset es √∫nica.")
    else:
        print("Supuesto de independencia de las observaciones (se cumple): se eliminan filas duplicadas, asegurando que cada fila representa una observaci√≥n √∫nica e independiente.")
    return df_filtered

def select_features(df):
    """
    Seleccionar caracter√≠sticas relevantes para el modelo de clasificaci√≥n.
    
    Excluimos:
    - Columnas derivadas (z-scores, marcadores de outliers) que podr√≠an
      causar fuga de datos o redundancia
    - Variable objetivo y sus variantes
    
    Mantenemos solo las caracter√≠sticas originales del dataset para
    que el modelo aprenda de informaci√≥n disponible al momento de
    la predicci√≥n.
    """
    # Patrones a excluir de las features
    exclude_patterns = ['_zscore', '_outlier', 'Target','Age','Target_encoded', 'Target_binary', '2nd sem', 'grade','enrolled', 'approved']
    exclude_exact = ['Nacionality', "Mother's occupation", 'Unemployment rate', 'Curricular units 1st sem (evaluations)','Tasa_aprobacion_1sem']

    # Filtrar columnas que no contengan ninguno de los patrones excluidos ni sean exactamente 'Nationality'
    feature_columns = [col for col in df.columns
                       if not any(pattern in col for pattern in exclude_patterns)
                       and col not in exclude_exact]

    print(f"\nüîß Features seleccionadas para el modelo: {len(feature_columns)}")

    return feature_columns

def verificar_linealidad_logit(df, features, target_col='Target_binary'):
    """
    Verifica la linealidad del logit para variables continuas usando Box-Tidwell y gr√°ficos.
    - Cada predictor continuo debe relacionarse linealmente con el logit de la probabilidad.
    - Si no se cumple, se recomienda transformar la variable.
    """

    print("\n" + "="*70)
    print("VERIFICACI√ìN DE LINEALIDAD DEL LOGIT (Box-Tidwell)")
    print("="*70)

    # Seleccionar variables continuas de la lista predefinida
    from sklearn.preprocessing import PowerTransformer
    lista_numericas = [
        'Age at enrollment',
        'GDP',
        'Inflation rate',
        'Unemployment rate',
        'Curricular units 1st sem (grade)',
        'Curricular units 1st sem (credited)',
        'Curricular units 1st sem (evaluations)',
        'Curricular units 1st sem (approved)', 
        'Curricular units 1st sem (without evaluations)', 
        'Tasa_aprobacion_1sem'
    ]
    continuous_vars = [col for col in features if col in lista_numericas and pd.api.types.is_numeric_dtype(df[col])]
    if not continuous_vars:
        print("No se encontraron variables continuas (de la lista definida y presentes en features) para verificar linealidad del logit.")
        return df
    df_num = df[continuous_vars].copy()

    # Box-Tidwell: agregar t√©rmino de interacci√≥n variable*log(variable)
    results = {}
    for var in continuous_vars:
        x = df_num[var].copy()
        x = pd.to_numeric(x, errors='coerce')
        n_nulos = x.isnull().sum()
        if n_nulos > 0:
            print(f"   ‚ö†Ô∏è {var}: {n_nulos} valores nulos/no num√©ricos eliminados para Box-Tidwell.")
        x = x.dropna()
        x = x.apply(lambda v: v if v > 0 else 1e-6)
        safe_var = f"var_{continuous_vars.index(var)}"
        safe_log = f"{safe_var}_log"
        df_bt = pd.DataFrame({
            safe_var: x,
            safe_log: x.apply(np.log),
            target_col: df.loc[x.index, target_col]
        })
        formula = f"{target_col} ~ {safe_var} + {safe_log}"
        try:
            model = logit(formula, data=df_bt).fit(disp=0)
            p_value = model.pvalues.get(safe_log, np.nan)
            results[var] = p_value
        except Exception as e:
            print(f"   ‚ö†Ô∏è No se pudo ajustar Box-Tidwell para {var}: {e}")
            results[var] = np.nan

    print("\nResultados Box-Tidwell (p-valor para t√©rmino log):\n" + "-"*55)
    no_lineales = []
    for var, pval in results.items():
        if np.isnan(pval):
            print(f"   ‚Ä¢ {var:<40} | No calculado")
        elif pval < 0.05:
            print(f"   ‚Ä¢ {var:<40} | ‚ùå p = {pval:.4f} | NO lineal, se intentar√° transformar")
            no_lineales.append(var)
        else:
            print(f"   ‚Ä¢ {var:<40} | ‚úÖ p = {pval:.4f} | Linealidad aceptable")
    print("-"*55 + "\n")

    # Intentar transformar variables no lineales
    transformaciones = {
        'log': lambda x: np.log(np.where(x > 0, x, 1e-6)),
        'sqrt': lambda x: np.sqrt(np.where(x >= 0, x, 0)),
        'square': lambda x: np.power(x, 2),
        'inverse': lambda x: 1.0 / np.where(x != 0, x, 1e-6),
        'yeo-johnson': None  # Usaremos PowerTransformer
    }
    cambios = {}
    for var in no_lineales:
        x_orig = pd.to_numeric(df[var], errors='coerce').fillna(1e-6)
        mejor_pval = None
        mejor_nombre = None
        mejor_x = None
        for nombre, func in transformaciones.items():
            if nombre == 'yeo-johnson':
                try:
                    pt = PowerTransformer(method='yeo-johnson')
                    x_tr = pt.fit_transform(x_orig.values.reshape(-1,1)).flatten()
                except Exception:
                    continue
            else:
                try:
                    x_tr = func(x_orig)
                except Exception:
                    continue
            # Box-Tidwell con variable transformada
            safe_var = 'var_tr'
            safe_log = 'var_tr_log'
            df_bt = pd.DataFrame({
                safe_var: x_tr,
                safe_log: np.log(np.where(x_tr > 0, x_tr, 1e-6)),
                target_col: df[target_col]
            })
            formula = f"{target_col} ~ {safe_var} + {safe_log}"
            try:
                model = logit(formula, data=df_bt).fit(disp=0)
                pval = model.pvalues.get(safe_log, np.nan)
                if not np.isnan(pval) and (mejor_pval is None or pval > mejor_pval):
                    mejor_pval = pval
                    mejor_nombre = nombre
                    mejor_x = x_tr
            except Exception:
                continue
        if mejor_pval is not None and mejor_pval >= 0.05:
            print(f"   ‚úÖ {var:<40} | Transformada con {mejor_nombre:<10} | p = {mejor_pval:.4f}\n")
            df[var] = mejor_x
            cambios[var] = mejor_nombre
        else:
            print(f"   ‚ö†Ô∏è {var:<40} | No pudo ser transformada para cumplir linealidad\n")

    if cambios:
        print("Variables transformadas para cumplir linealidad:\n" + "-"*55)
        for var, trans in cambios.items():
            print(f"   ‚Ä¢ {var:<40} | {trans}")
        print("-"*55 + "\n")
    else:
        print("No se realizaron transformaciones autom√°ticas.\n")

    # Inspecci√≥n gr√°fica
    print("\nInspecci√≥n gr√°fica de la relaci√≥n logit vs variable continua:")
    n_vars = len(continuous_vars)
    if n_vars == 0:
        print("No hay variables continuas para graficar.")
        return df
    ncols = 2
    nrows = (n_vars + ncols - 1) // ncols
    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6*ncols, 4*nrows))
    if n_vars == 1:
        axes = [axes]
    else:
        axes = axes.flatten()
    for idx, var in enumerate(continuous_vars):
        ax = axes[idx]
        try:
            X = sm.add_constant(df[var])
            y = df[target_col]
            model = sm.Logit(y, X).fit(disp=0)
            logit_pred = model.predict(X)
            ax.scatter(df[var], logit_pred, alpha=0.3)
            ax.set_xlabel(var)
            ax.set_ylabel('Logit estimado')
            ax.set_title(f'Logit vs {var}')
            ax.grid(True, alpha=0.3)
        except Exception as e:
            ax.text(0.5, 0.5, f"No se pudo graficar\n{var}\n{e}", ha='center', va='center', fontsize=10)
            print(f"   ‚ö†Ô∏è No se pudo graficar {var}: {e}")
    for j in range(idx+1, len(axes)):
        fig.delaxes(axes[j])
    plt.tight_layout(pad=1.0, h_pad=1.0)
    plt.show()

    print("\nSi alguna variable muestra relaci√≥n no lineal, considerar transformar (log, ra√≠z, polinomio) o categorizar.")
    return df

def verificar_multicolinealidad(df, features, threshold=10.0):
    """
    Verifica la ausencia de multicolinealidad fuerte entre predictores.
    - Calcula VIF (Variance Inflation Factor) para cada variable num√©rica.
    - Si VIF > threshold, hay multicolinealidad fuerte.
    """

    print("\n" + "="*70)
    print("VERIFICACI√ìN DE MULTICOLINEALIDAD (VIF y correlaci√≥n)")
    print("="*70)

    # Seleccionar solo variables num√©ricas
    df_num = df[features].select_dtypes(include=[np.number]).copy()
    if df_num.shape[1] < 2:
        print("No hay suficientes variables num√©ricas para analizar multicolinealidad.")
        return

    # Calcular VIF
    vif_data = pd.DataFrame()
    vif_data['Variable'] = df_num.columns
    vif_data['VIF'] = [variance_inflation_factor(df_num.values, i) for i in range(df_num.shape[1])]

    print("\nValores de VIF:")
    for _, row in vif_data.iterrows():
        if row['VIF'] > threshold:
            print(f"   - {row['Variable']}: ‚ùå VIF = {row['VIF']:.2f} (multicolinealidad fuerte)")
        else:
            print(f"   - {row['Variable']}: ‚úÖ VIF = {row['VIF']:.2f}")

    # Calcular porcentajes de variables en rangos de VIF
    total_vars = len(vif_data)
    count_1_2 = ((vif_data['VIF'] >= 1) & (vif_data['VIF'] < 2)).sum()
    count_2_5 = ((vif_data['VIF'] >= 2) & (vif_data['VIF'] < 5)).sum()
    count_5_10 = ((vif_data['VIF'] >= 5) & (vif_data['VIF'] < 10)).sum()
    pct_1_2 = count_1_2 / total_vars * 100 if total_vars > 0 else 0
    pct_2_5 = count_2_5 / total_vars * 100 if total_vars > 0 else 0
    pct_5_10 = count_5_10 / total_vars * 100 if total_vars > 0 else 0
    print("\nDistribuci√≥n de VIF en variables predictoras:")
    print(f"   - VIF entre 1 y 2:    {count_1_2} variables ({pct_1_2:.1f}%)")
    print(f"   - VIF entre 2 y 5:    {count_2_5} variables ({pct_2_5:.1f}%)")
    print(f"   - VIF entre 5 y 10:   {count_5_10} variables ({pct_5_10:.1f}%)")

def verificar_tamanio_muestra_epv(df, features, target_col='Target_binary', epv_min=10):
    """
    Verifica si el tama√±o de muestra es adecuado para regresi√≥n log√≠stica seg√∫n la regla cl√°sica:
    - EPV (eventos por predictor) ‚â• 10
    - EPV = min(n_eventos_clase_1, n_eventos_clase_0) / n_predictors
    """
    print("\n" + "="*70)
    print("VERIFICACI√ìN DE TAMA√ëO DE MUESTRA (Regla cl√°sica EPV ‚â• 10)")
    print("="*70)
    
    n_obs = len(df)
    n_vars = len(features)
    n_eventos_1 = (df[target_col] == 1).sum()
    n_eventos_0 = (df[target_col] == 0).sum()
    epv = min(n_eventos_1, n_eventos_0) / n_vars if n_vars > 0 else 0
    print(f"Total de observaciones: {n_obs}")
    print(f"Variables predictoras: {n_vars}")
    print(f"Eventos clase 1 (Graduate): {n_eventos_1}")
    print(f"Eventos clase 0 (Dropout): {n_eventos_0}")
    print(f"EPV (eventos por predictor): {epv:.2f}")
    print(f"M√≠nimo recomendado (EPV ‚â• {epv_min})")
    if epv >= epv_min:
        print("\n‚úÖ Tama√±o de muestra adecuado seg√∫n la regla cl√°sica EPV ‚â• 10.")
    else:
        print("\n‚ö†Ô∏è Tama√±o de muestra POTENCIALMENTE INSUFICIENTE para la cantidad de predictores. Considere reducir el n√∫mero de variables o recolectar m√°s datos.")
    def verificar_tamanio_muestra(df, features, target_col='Target_binary', min_per_variable=10):
        """
        Verifica si el tama√±o de muestra es adecuado para la regresi√≥n log√≠stica.
        Regla com√∫n: al menos 10 casos por variable predictora para cada clase de la variable objetivo.
        """
        print("\n==============================")
        print("VERIFICACI√ìN DE TAMA√ëO DE MUESTRA ADECUADO")
        print("==============================")
        n_obs = len(df)
        n_vars = len(features)
        n_success = (df[target_col] == 1).sum()
        n_failure = (df[target_col] == 0).sum()
        min_class = min(n_success, n_failure)
        min_required = n_vars * min_per_variable
        print(f"Total de observaciones: {n_obs}")
        print(f"Variables predictoras: {n_vars}")
        print(f"Casos clase 1 (√©xito): {n_success}")
        print(f"Casos clase 0 (abandono): {n_failure}")
        print(f"Casos m√≠nimos por clase: {min_class}")
        print(f"M√≠nimo recomendado (10 por variable): {min_required}")
        if min_class >= min_required:
            print("\n‚úÖ Tama√±o de muestra adecuado para la regresi√≥n log√≠stica.")
        else:
            print("\n‚ö†Ô∏è Tama√±o de muestra POTENCIALMENTE INSUFICIENTE para la cantidad de variables. Considere reducir el n√∫mero de predictores o recolectar m√°s datos.")
        print("Nota: Esta es una regla emp√≠rica. Si el modelo converge y los resultados son estables, puede ser aceptable con menos casos, pero aumenta el riesgo de sobreajuste.")

def prepare_train_test_split(df, feature_columns):
    """
    Preparar conjuntos de entrenamiento y prueba con estratificaci√≥n.
    Divisi√≥n t√≠pica: 80% entrenamiento, 20% prueba
    """
    X = df[feature_columns]   # Variables predictoras (features)
    y = df['Target_binary']   # Variable objetivo (0=Dropout, 1=Graduate)
    
    # Dividir manteniendo proporci√≥n de clases
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=TEST_SIZE, 
        random_state=RANDOM_STATE,
        stratify=y  # Mantener proporci√≥n de Dropout/Graduate en ambos sets
    )
    
    print(f"\nüìä Divisi√≥n de datos:")
    print(f"   - Conjunto de entrenamiento: {len(X_train)} ({100-TEST_SIZE*100:.0f}%)")
    print(f"   - Conjunto de prueba: {len(X_test)} ({TEST_SIZE*100:.0f}%)")
    
    # Verify stratification
    print(f"\nüìä Distribuci√≥n en entrenamiento:")
    print(f"   - Graduados: {sum(y_train)} ({sum(y_train)/len(y_train)*100:.1f}%)")
    print(f"   - Deserci√≥n: {len(y_train)-sum(y_train)} ({(len(y_train)-sum(y_train))/len(y_train)*100:.1f}%)")
    
    return X_train, X_test, y_train, y_test

def scale_features(X_train, X_test):
    """
    Estandarizar features para regresi√≥n log√≠stica.
    
    La estandarizaci√≥n (StandardScaler) transforma cada variable para que tenga:
    - Media = 0
    - Desviaci√≥n est√°ndar = 1
    """
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)  # Ajustar y transformar
    X_test_scaled = scaler.transform(X_test)        # Solo transformar
    
    return X_train_scaled, X_test_scaled, scaler

def train_logistic_regression(X_train, y_train):
    """
    Entrenar modelo de regresi√≥n log√≠stica con regularizaci√≥n.
    """
    print("\n" + "=" * 70)
    print("ENTRENAMIENTO DEL MODELO DE REGRESI√ìN LOG√çSTICA")
    print("=" * 70)
    
    # Configurar y entrenar el modelo
    model = LogisticRegression(
        penalty='l2',           # Regularizaci√≥n L2 (Ridge) para evitar sobreajuste
        C=1.0,                  # Inverso de la fuerza de regularizaci√≥n
        solver='lbfgs',         # Algoritmo de optimizaci√≥n quasi-Newton
        max_iter=1000,          # M√°ximo de iteraciones para convergencia
        random_state=RANDOM_STATE,
        class_weight='balanced' # Compensar desbalance entre clases
    )
    
    model.fit(X_train, y_train)  # Ajustar modelo a datos de entrenamiento
    
    print("\n‚úÖ Modelo entrenado exitosamente")
    print(f"   - Regularizaci√≥n: L2 (Ridge)")
    print(f"   - Solver: LBFGS")
    print(f"   - Class weight: Balanced")
    
    return model

def perform_cross_validation(model, X_train, y_train):
    """
    Realizar validaci√≥n cruzada k-fold para evaluar estabilidad del modelo.
    
    Validaci√≥n cruzada (5-fold):
    1. Divide los datos en 5 partes iguales
    2. Entrena en 4 partes, eval√∫a en la 5ta
    3. Repite 5 veces, cada parte siendo el conjunto de prueba una vez
    4. Promedia los resultados
    """
    print("\n" + "=" * 70)
    print("VALIDACI√ìN CRUZADA (5-FOLD)")
    print("=" * 70)
    
    # Configurar validaci√≥n cruzada estratificada
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)
    
    # Evaluar m√∫ltiples m√©tricas usando validaci√≥n cruzada
    cv_accuracy = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')
    cv_precision = cross_val_score(model, X_train, y_train, cv=cv, scoring='precision')
    cv_recall = cross_val_score(model, X_train, y_train, cv=cv, scoring='recall')
    cv_f1 = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')
    cv_roc_auc = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc')
    
    print("\nüìä Resultados de Validaci√≥n Cruzada (5 folds):")
    print(f"\n   {'M√©trica':<15} {'Media':>10} {'Desv. Est.':>12} {'Min':>10} {'Max':>10}")
    print("   " + "-" * 57)
    print(f"   {'Accuracy':<15} {cv_accuracy.mean():>10.4f} {cv_accuracy.std():>12.4f} {cv_accuracy.min():>10.4f} {cv_accuracy.max():>10.4f}")
    print(f"   {'Precision':<15} {cv_precision.mean():>10.4f} {cv_precision.std():>12.4f} {cv_precision.min():>10.4f} {cv_precision.max():>10.4f}")
    print(f"   {'Recall':<15} {cv_recall.mean():>10.4f} {cv_recall.std():>12.4f} {cv_recall.min():>10.4f} {cv_recall.max():>10.4f}")
    print(f"   {'F1-Score':<15} {cv_f1.mean():>10.4f} {cv_f1.std():>12.4f} {cv_f1.min():>10.4f} {cv_f1.max():>10.4f}")
    print(f"   {'ROC-AUC':<15} {cv_roc_auc.mean():>10.4f} {cv_roc_auc.std():>12.4f} {cv_roc_auc.min():>10.4f} {cv_roc_auc.max():>10.4f}")
    
    cv_results = {
        'accuracy': {'mean': cv_accuracy.mean(), 'std': cv_accuracy.std(), 'values': cv_accuracy.tolist()},
        'precision': {'mean': cv_precision.mean(), 'std': cv_precision.std(), 'values': cv_precision.tolist()},
        'recall': {'mean': cv_recall.mean(), 'std': cv_recall.std(), 'values': cv_recall.tolist()},
        'f1': {'mean': cv_f1.mean(), 'std': cv_f1.std(), 'values': cv_f1.tolist()},
        'roc_auc': {'mean': cv_roc_auc.mean(), 'std': cv_roc_auc.std(), 'values': cv_roc_auc.tolist()}
    }
    
    return cv_results

def evaluate_model(model, X_test, y_test, feature_names):
    """
    Evaluaci√≥n completa del modelo en el conjunto de prueba.
    
    M√©tricas calculadas:
    - Accuracy: proporci√≥n de predicciones correctas totales
    - Precision: de los predichos como Graduate, ¬øcu√°ntos realmente lo son?
    - Recall: de los Graduate reales, ¬øcu√°ntos identificamos?
    - F1-Score: media arm√≥nica de precision y recall
    - ROC-AUC: capacidad de distinguir entre clases (0.5=azar, 1=perfecto)
    - Average Precision: resumen de curva precision-recall
    
    Matriz de confusi√≥n:
    - Verdaderos Negativos (TN): Dropout predicho correctamente
    - Falsos Positivos (FP): Dropout predicho como Graduate (error Tipo I)
    - Falsos Negativos (FN): Graduate predicho como Dropout (error Tipo II)
    - Verdaderos Positivos (TP): Graduate predicho correctamente
    """
    print("\n" + "=" * 70)
    print("EVALUACI√ìN DEL MODELO EN CONJUNTO DE PRUEBA")
    print("=" * 70)
    
    # Generar predicciones
    y_pred = model.predict(X_test)              # Clase predicha (0 o 1)
    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilidad de Graduate
    
    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    avg_precision = average_precision_score(y_test, y_pred_proba)
    
    print("\nüìä M√©tricas de Rendimiento:")
    print(f"\n   {'M√©trica':<25} {'Valor':>10}")
    print("   " + "-" * 35)
    print(f"   {'Accuracy (Exactitud)':<25} {accuracy:>10.4f}")
    print(f"   {'Precision':<25} {precision:>10.4f}")
    print(f"   {'Recall (Sensibilidad)':<25} {recall:>10.4f}")
    print(f"   {'F1-Score':<25} {f1:>10.4f}")
    print(f"   {'ROC-AUC':<25} {roc_auc:>10.4f}")
    print(f"   {'Average Precision':<25} {avg_precision:>10.4f}")
    
    # Classification Report
    print("\nüìä Reporte de Clasificaci√≥n Detallado:")
    print("\n" + classification_report(y_test, y_pred, 
                                       target_names=['Dropout (0)', 'Graduate (1)']))
    
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    print("\nüìä Matriz de Confusi√≥n:")
    print(f"\n                    Predicho")
    print(f"                 Dropout  Graduate")
    print(f"   Real Dropout    {cm[0][0]:>5}    {cm[0][1]:>5}")
    print(f"   Real Graduate   {cm[1][0]:>5}    {cm[1][1]:>5}")
    
    # Interpretation
    tn, fp, fn, tp = cm.ravel()
    print(f"\n   ‚úÖ Verdaderos Negativos (Dropout correctamente predicho): {tn}")
    print(f"   ‚ùå Falsos Positivos (Dropout predicho como Graduate): {fp}")
    print(f"   ‚ùå Falsos Negativos (Graduate predicho como Dropout): {fn}")
    print(f"   ‚úÖ Verdaderos Positivos (Graduate correctamente predicho): {tp}")
    
    metrics = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'roc_auc': roc_auc,
        'average_precision': avg_precision,
        'confusion_matrix': cm.tolist(),
        'true_negatives': int(tn),
        'false_positives': int(fp),
        'false_negatives': int(fn),
        'true_positives': int(tp)
    }
    
    return metrics, y_pred, y_pred_proba

def analyze_feature_importance(model, feature_names):
    """
    Analizar y clasificar la importancia de variables basada en coeficientes.
    
    En regresi√≥n log√≠stica, los coeficientes indican:
    - Coeficiente > 0: aumenta probabilidad de Graduate
    - Coeficiente < 0: aumenta probabilidad de Dropout
    
    Odds Ratio (OR) = exp(coeficiente):
    - OR > 1: factor favorece graduaci√≥n
    - OR < 1: factor favorece abandono
    - OR = 1: sin efecto
    
    """
    print("\n" + "=" * 70)
    print("AN√ÅLISIS DE IMPORTANCIA DE VARIABLES")
    print("=" * 70)
    
    # Obtener coeficientes del modelo entrenado
    coefficients = model.coef_[0]
    
    # Crear DataFrame con m√©tricas de importancia
    feature_importance = pd.DataFrame({
        'Feature': feature_names,
        'Coefficient': coefficients,
        'Abs_Coefficient': np.abs(coefficients),  # Valor absoluto para ordenar
        'Odds_Ratio': np.exp(coefficients)        # Transformar a odds ratio
    }).sort_values('Abs_Coefficient', ascending=False)
    
    print("\nüìä Top 12 Variables m√°s Importantes (por magnitud del coeficiente):")
    print("\n   " + "-" * 75)
    print(f"   {'#':<3} {'Variable':<45} {'Coef.':>10} {'Odds Ratio':>12}")
    print("   " + "-" * 75)
    
    for i, (_, row) in enumerate(feature_importance.head(12).iterrows()):
        effect = "‚Üë Graduate" if row['Coefficient'] > 0 else "‚Üì Dropout"
        print(f"   {i+1:<3} {row['Feature']:<45} {row['Coefficient']:>10.4f} {row['Odds_Ratio']:>12.4f}")
    
    print("\nüìñ Interpretaci√≥n de Odds Ratio:")
    print("   - Odds Ratio > 1: Mayor probabilidad de GRADUARSE")
    print("   - Odds Ratio < 1: Mayor probabilidad de ABANDONAR")
    print("   - Odds Ratio = 1: Variable no tiene efecto")
    
    # Key findings
    print("\nüîç Hallazgos Clave:")
    
    # Top positive factors (increase graduation probability)
    positive_factors = feature_importance[feature_importance['Coefficient'] > 0].head(5)
    print("\n   üìà Factores que AUMENTAN la probabilidad de graduarse:")
    for _, row in positive_factors.iterrows():
        print(f"      ‚Ä¢ {row['Feature']}: OR = {row['Odds_Ratio']:.3f}")
    
    # Top negative factors (increase dropout probability)
    negative_factors = feature_importance[feature_importance['Coefficient'] < 0].head(5)
    print("\n   üìâ Factores que AUMENTAN la probabilidad de abandono:")
    for _, row in negative_factors.iterrows():
        print(f"      ‚Ä¢ {row['Feature']}: OR = {row['Odds_Ratio']:.3f}")
    
    return feature_importance

def create_visualizations(model, X_test, y_test, y_pred, y_pred_proba, 
                          feature_importance, metrics, output_dir):
    """
    Crear visualizaciones completas para los resultados de clasificaci√≥n.
    
    Gr√°ficos generados:
    1. Matriz de confusi√≥n: visualiza aciertos y errores del modelo
    2. Curva ROC: capacidad de discriminaci√≥n a diferentes umbrales
    3. Curva Precision-Recall: rendimiento en diferentes puntos de corte
    4. Importancia de features: qu√© variables influyen m√°s
    5. Distribuci√≥n de probabilidades: separaci√≥n entre clases
    6. Resumen de m√©tricas: vista general del rendimiento
    
    Tambi√©n genera gr√°fico separado de Odds Ratios para interpretaci√≥n.
    """
    print("\n" + "=" * 70)
    print("GENERACI√ìN DE VISUALIZACIONES")
    print("=" * 70)
    
    # Solo lo esencial: matriz de confusi√≥n, curva ROC, importancia de variables y resumen de m√©tricas
    fig, axs = plt.subplots(2, 2, figsize=(14, 10))

    # Matriz de confusi√≥n
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axs[0, 0])
    axs[0, 0].set_title('Matriz de Confusi√≥n')
    axs[0, 0].set_xlabel('Predicci√≥n')
    axs[0, 0].set_ylabel('Valor Real')

    # Curva ROC
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    axs[0, 1].plot(fpr, tpr, label=f'ROC (AUC = {metrics["roc_auc"]:.2f})')
    axs[0, 1].plot([0, 1], [0, 1], 'r--', label='Aleatorio')
    axs[0, 1].set_title('Curva ROC')
    axs[0, 1].set_xlabel('Falsos Positivos')
    axs[0, 1].set_ylabel('Verdaderos Positivos')
    axs[0, 1].legend()

    # Importancia de variables (Top 10)
    top_features = feature_importance.head(10)
    axs[1, 0].barh(top_features['Feature'], top_features['Coefficient'], color='skyblue')
    axs[1, 0].set_title('Top 10 Variables')
    axs[1, 0].set_xlabel('Coeficiente')
    axs[1, 0].invert_yaxis()

    # Resumen de m√©tricas
    names = ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC-AUC']
    values = [metrics['accuracy'], metrics['precision'], metrics['recall'], metrics['f1_score'], metrics['roc_auc']]
    axs[1, 1].bar(names, values, color='lightgreen')
    axs[1, 1].set_ylim(0, 1)
    axs[1, 1].set_title('M√©tricas')
    for i, v in enumerate(values):
        axs[1, 1].text(i, v + 0.02, f'{v:.2f}', ha='center', fontweight='bold')

    plt.tight_layout()
    fig_path = os.path.join(output_dir, 'resultados_esenciales.png')

    plt.savefig(fig_path, dpi=300, bbox_inches='tight')
    plt.show()  # Mostrar la imagen en una ventana de matplotlib
    plt.close()

    print(f"\n‚úÖ Visualizaci√≥n esencial guardada en: {fig_path}")
    return [fig_path]

def save_results(metrics, cv_results, feature_importance, output_dir):
    """
    Save all results to JSON file.
    """
    results = {
        'timestamp': datetime.now().isoformat(),
        'model': 'Logistic Regression',
        'parameters': {
            'penalty': 'l2',
            'C': 1.0,
            'solver': 'lbfgs',
            'class_weight': 'balanced',
            'test_size': TEST_SIZE,
            'random_state': RANDOM_STATE
        },
        'cross_validation': cv_results,
        'test_metrics': metrics,
        'feature_importance': feature_importance.to_dict('records')
    }
    
    results_path = os.path.join(output_dir, 'classification_report.json')
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    # Save feature importance to CSV
    fi_path = os.path.join(output_dir, 'feature_importance.csv')
    feature_importance.to_csv(fi_path, index=False)
    
    print(f"\n‚úÖ Resultados guardados en: {results_path}")
    print(f"‚úÖ Importancia de variables guardada en: {fi_path}")
    
    return results_path, fi_path

def generate_conclusions(metrics, cv_results, feature_importance):
    """
    Generar conclusiones finales y responder a la pregunta de investigaci√≥n.
    
    Criterios de evaluaci√≥n del rendimiento (basados en ROC-AUC):
    - >= 0.85: Excelente - modelo muy confiable
    - >= 0.75: Bueno - modelo √∫til para aplicaciones pr√°cticas
    - >= 0.65: Moderado - modelo tiene valor pero con limitaciones
    - < 0.65: Limitado - requiere mejoras significativas
    
    Esta funci√≥n proporciona:
    - Respuesta directa a la pregunta de investigaci√≥n
    - Resumen de m√©tricas clave
    - Identificaci√≥n de factores predictivos importantes
    - Implicaciones pr√°cticas para intervenci√≥n
    - Limitaciones y consideraciones √©ticas
    """
    print("\n" + "=" * 70)
    print("CONCLUSIONES Y RESPUESTA A LA PREGUNTA DE INVESTIGACI√ìN")
    print("=" * 70)
    
    print("""
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PREGUNTA DE INVESTIGACI√ìN                                               ‚îÇ
‚îÇ  "¬øEs posible predecir el abandono acad√©mico o √©xito de un estudiante   ‚îÇ
‚îÇ   utilizando t√©cnicas estad√≠sticas y de clasificaci√≥n?"                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    """)
    
    # Determine answer based on metrics
    accuracy = metrics['accuracy']
    roc_auc = metrics['roc_auc']
    f1 = metrics['f1_score']
    
    if roc_auc >= 0.85:
        performance_level = "EXCELENTE"
        answer = "S√ç, definitivamente"
    elif roc_auc >= 0.75:
        performance_level = "BUENO"
        answer = "S√ç, con buena precisi√≥n"
    elif roc_auc >= 0.65:
        performance_level = "MODERADO"
        answer = "S√ç, con precisi√≥n moderada"
    else:
        performance_level = "LIMITADO"
        answer = "Parcialmente, con limitaciones"
    
    print(f"""
üìä RESPUESTA: {answer}

El modelo de Regresi√≥n Log√≠stica demuestra un rendimiento {performance_level} 
en la predicci√≥n del abandono acad√©mico y √©xito estudiantil:

   üìà M√©tricas de Rendimiento:
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ ‚Ä¢ Accuracy (Exactitud):        {accuracy:.1%}                           ‚îÇ
   ‚îÇ ‚Ä¢ ROC-AUC:                     {roc_auc:.1%}                           ‚îÇ
   ‚îÇ ‚Ä¢ F1-Score:                    {f1:.1%}                           ‚îÇ
   ‚îÇ ‚Ä¢ Cross-Validation Accuracy:   {cv_results['accuracy']['mean']:.1%} (¬±{cv_results['accuracy']['std']:.1%})     ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    """)
    
    # Key predictive factors
    top_positive = feature_importance[feature_importance['Coefficient'] > 0].head(3)
    top_negative = feature_importance[feature_importance['Coefficient'] < 0].head(3)
    
    print("""
üîç FACTORES PREDICTIVOS CLAVE:

   ‚úÖ Factores que PREDICEN √âXITO (Graduaci√≥n):""")
    for _, row in top_positive.iterrows():
        print(f"      ‚Ä¢ {row['Feature']}")
    
    print("""
   ‚ùå Factores que PREDICEN ABANDONO:""")
    for _, row in top_negative.iterrows():
        print(f"      ‚Ä¢ {row['Feature']}")
    
    print("""
üí° IMPLICACIONES PR√ÅCTICAS:

   1. DETECCI√ìN TEMPRANA: El modelo puede identificar estudiantes en riesgo
      de abandono al inicio de su carrera acad√©mica.
   
   2. INTERVENCI√ìN FOCALIZADA: Las variables identificadas pueden guiar
      programas de apoyo estudiantil hacia factores modificables.
   
   3. ASIGNACI√ìN DE RECURSOS: Permite priorizar recursos de apoyo hacia
      estudiantes con mayor probabilidad de abandono.

üìã LIMITACIONES Y CONSIDERACIONES:

   ‚Ä¢ El modelo se basa en datos hist√≥ricos y patrones pasados
   ‚Ä¢ Factores externos no medidos pueden influir en el resultado
   ‚Ä¢ Las predicciones deben usarse como herramienta de apoyo, no como
     determinantes absolutos del futuro de un estudiante
   ‚Ä¢ Se recomienda combinar con evaluaci√≥n cualitativa

üéØ RECOMENDACI√ìN FINAL:

   El an√°lisis confirma que ES POSIBLE predecir con """ + performance_level.lower() + """ precisi√≥n
   el abandono acad√©mico utilizando t√©cnicas de regresi√≥n log√≠stica. Este modelo
   puede ser una herramienta valiosa para instituciones educativas en la
   identificaci√≥n temprana de estudiantes que requieren apoyo adicional.
    """)

def main():
    # 1. Cargar y preparar datos
    df = load_and_prepare_data(INPUT_PATH)

    # 2. Seleccionar features
    feature_columns = select_features(df)

    # 3. Verificar linealidad del logit y transformar variables si es necesario
    df = verificar_linealidad_logit(df, feature_columns, target_col='Target_binary')

    # 4. Verificar multicolinealidad
    verificar_multicolinealidad(df, feature_columns, threshold=10.0)

    # 5. Verificar tama√±o de muestra EPV
    verificar_tamanio_muestra_epv(df, feature_columns, target_col='Target_binary', epv_min=10)

    # 6. Preparar conjuntos de entrenamiento y prueba
    X_train, X_test, y_train, y_test = prepare_train_test_split(df, feature_columns)

    # 7. Estandarizar features
    X_train_scaled, X_test_scaled, scaler = scale_features(X_train, X_test)

    # 8. Entrenar modelo de regresi√≥n log√≠stica
    model = train_logistic_regression(X_train_scaled, y_train)

    # 9. Validaci√≥n cruzada
    cv_results = perform_cross_validation(model, X_train_scaled, y_train)

    # 10. Evaluar modelo en conjunto de prueba
    metrics, y_pred, y_pred_proba = evaluate_model(model, X_test_scaled, y_test, feature_columns)

    # 11. Analizar importancia de variables
    feature_importance = analyze_feature_importance(model, feature_columns)

    # 12. Crear visualizaciones
    output_dir = os.path.join('outputs', 'prediction_results')
    os.makedirs(output_dir, exist_ok=True)
    create_visualizations(model, X_test_scaled, y_test, y_pred, y_pred_proba, feature_importance, metrics, output_dir)

    # 13. Guardar resultados
    save_results(metrics, cv_results, feature_importance, output_dir)

    # 14. Generar conclusiones
    generate_conclusions(metrics, cv_results, feature_importance)

if __name__ == "__main__":
    main()